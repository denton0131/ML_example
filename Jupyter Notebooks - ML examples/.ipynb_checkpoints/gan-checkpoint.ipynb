{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Generative Adversarial Network Example\n",
    "\n",
    "Build a generative adversarial network (GAN) to generate digit images from a noise distribution with TensorFlow.\n",
    "\n",
    "- Author: Aymeric Damien\n",
    "- Project: https://github.com/aymericdamien/TensorFlow-Examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Overview\n",
    "\n",
    "<img src=\"http://www.timzhangyuxuan.com/static/images/project_DCGAN/structure.png\" alt=\"nn\" style=\"width: 800px;\"/>\n",
    "\n",
    "References:\n",
    "- [Generative adversarial nets](https://arxiv.org/pdf/1406.2661.pdf). I Goodfellow, J Pouget-Abadie, M Mirza, B Xu, D Warde-Farley, S Ozair, Y. Bengio. Advances in neural information processing systems, 2672-2680.\n",
    "- [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a.html). X Glorot, Y Bengio. Aistats 9, 249-256\n",
    "\n",
    "Other tutorials:\n",
    "- [Generative Adversarial Networks Explained](http://kvfrans.com/generative-adversial-networks-explained/). Kevin Frans.\n",
    "\n",
    "## MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flattened and converted to a 1-D numpy array of 784 features (28*28).\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "More info: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-2f44eee0991e>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\marku\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\marku\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\marku\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\marku\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\marku\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Params\n",
    "num_steps = 70000\n",
    "batch_size = 128\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# Network Params\n",
    "image_dim = 784 # 28*28 pixels\n",
    "gen_hidden_dim = 256\n",
    "disc_hidden_dim = 256\n",
    "noise_dim = 100 # Noise data points\n",
    "\n",
    "# A custom initialization (see Xavier Glorot init)\n",
    "def glorot_init(shape):\n",
    "    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\marku\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'gen_hidden1': tf.Variable(glorot_init([noise_dim, gen_hidden_dim])),\n",
    "    'gen_out': tf.Variable(glorot_init([gen_hidden_dim, image_dim])),\n",
    "    'disc_hidden1': tf.Variable(glorot_init([image_dim, disc_hidden_dim])),\n",
    "    'disc_out': tf.Variable(glorot_init([disc_hidden_dim, 1])),\n",
    "}\n",
    "biases = {\n",
    "    'gen_hidden1': tf.Variable(tf.zeros([gen_hidden_dim])),\n",
    "    'gen_out': tf.Variable(tf.zeros([image_dim])),\n",
    "    'disc_hidden1': tf.Variable(tf.zeros([disc_hidden_dim])),\n",
    "    'disc_out': tf.Variable(tf.zeros([1])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "def generator(x):\n",
    "    hidden_layer = tf.matmul(x, weights['gen_hidden1'])\n",
    "    hidden_layer = tf.add(hidden_layer, biases['gen_hidden1'])\n",
    "    hidden_layer = tf.nn.relu(hidden_layer)\n",
    "    out_layer = tf.matmul(hidden_layer, weights['gen_out'])\n",
    "    out_layer = tf.add(out_layer, biases['gen_out'])\n",
    "    out_layer = tf.nn.sigmoid(out_layer)\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "def discriminator(x):\n",
    "    hidden_layer = tf.matmul(x, weights['disc_hidden1'])\n",
    "    hidden_layer = tf.add(hidden_layer, biases['disc_hidden1'])\n",
    "    hidden_layer = tf.nn.relu(hidden_layer)\n",
    "    out_layer = tf.matmul(hidden_layer, weights['disc_out'])\n",
    "    out_layer = tf.add(out_layer, biases['disc_out'])\n",
    "    out_layer = tf.nn.sigmoid(out_layer)\n",
    "    return out_layer\n",
    "\n",
    "# Build Networks\n",
    "# Network Inputs\n",
    "gen_input = tf.placeholder(tf.float32, shape=[None, noise_dim], name='input_noise')\n",
    "disc_input = tf.placeholder(tf.float32, shape=[None, image_dim], name='disc_input')\n",
    "\n",
    "# Build Generator Network\n",
    "gen_sample = generator(gen_input)\n",
    "\n",
    "# Build 2 Discriminator Networks (one from noise input, one from generated samples)\n",
    "disc_real = discriminator(disc_input)\n",
    "disc_fake = discriminator(gen_sample)\n",
    "\n",
    "# Build Loss\n",
    "gen_loss = -tf.reduce_mean(tf.log(disc_fake))\n",
    "disc_loss = -tf.reduce_mean(tf.log(disc_real) + tf.log(1. - disc_fake))\n",
    "\n",
    "# Build Optimizers\n",
    "optimizer_gen = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer_disc = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# Training Variables for each optimizer\n",
    "# By default in TensorFlow, all variables are updated by each optimizer, so we\n",
    "# need to precise for each one of them the specific variables to update.\n",
    "# Generator Network Variables\n",
    "gen_vars = [weights['gen_hidden1'], weights['gen_out'],\n",
    "            biases['gen_hidden1'], biases['gen_out']]\n",
    "# Discriminator Network Variables\n",
    "disc_vars = [weights['disc_hidden1'], weights['disc_out'],\n",
    "            biases['disc_hidden1'], biases['disc_out']]\n",
    "\n",
    "# Create training operations\n",
    "train_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\n",
    "train_disc = optimizer_disc.minimize(disc_loss, var_list=disc_vars)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Generator Loss: 1.458171, Discriminator Loss: 1.257894\n",
      "Step 2000: Generator Loss: 4.970426, Discriminator Loss: 0.023515\n",
      "Step 4000: Generator Loss: 3.421590, Discriminator Loss: 0.105243\n"
     ]
    }
   ],
   "source": [
    "# Start Training\n",
    "# Start a new TF session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "# Training\n",
    "for i in range(1, num_steps+1):\n",
    "    # Prepare Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "    # Generate noise to feed to the generator\n",
    "    z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
    "\n",
    "    # Train\n",
    "    feed_dict = {disc_input: batch_x, gen_input: z}\n",
    "    _, _, gl, dl = sess.run([train_gen, train_disc, gen_loss, disc_loss],\n",
    "                            feed_dict=feed_dict)\n",
    "    if i % 2000 == 0 or i == 1:\n",
    "        print('Step %i: Generator Loss: %f, Discriminator Loss: %f' % (i, gl, dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing\n",
    "# Generate images from noise, using the generator network.\n",
    "n = 1\n",
    "canvas = np.empty((28 * n, 28 * n))\n",
    "for i in range(n):\n",
    "    # Noise input.\n",
    "    z = np.random.uniform(-1., 1., size=[n, noise_dim])\n",
    "    # Generate image from noise.\n",
    "    g = sess.run(gen_sample, feed_dict={gen_input: z})\n",
    "    # Reverse colours for better display\n",
    "    g = -1 * (g - 1)\n",
    "    for j in range(n):\n",
    "        # Draw the generated digits\n",
    "        canvas[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n",
    "\n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
